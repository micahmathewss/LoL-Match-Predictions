{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e125a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: /Users/micah.mathews/Documents/wager_ai/lol_data/data_extraction/2023_LoL_esports_match_data_from_OraclesElixir.csv\n",
      "Downloaded: /Users/micah.mathews/Documents/wager_ai/lol_data/data_extraction/2022_LoL_esports_match_data_from_OraclesElixir.csv\n",
      "Downloaded: /Users/micah.mathews/Documents/wager_ai/lol_data/data_extraction/2021_LoL_esports_match_data_from_OraclesElixir.csv\n",
      "Downloaded: /Users/micah.mathews/Documents/wager_ai/lol_data/data_extraction/2020_LoL_esports_match_data_from_OraclesElixir.csv\n",
      "Downloaded: /Users/micah.mathews/Documents/wager_ai/lol_data/data_extraction/2019_LoL_esports_match_data_from_OraclesElixir.csv\n",
      "Downloaded: /Users/micah.mathews/Documents/wager_ai/lol_data/data_extraction/2018_LoL_esports_match_data_from_OraclesElixir.csv\n",
      "Downloaded: /Users/micah.mathews/Documents/wager_ai/lol_data/data_extraction/2017_LoL_esports_match_data_from_OraclesElixir.csv\n",
      "Downloaded: /Users/micah.mathews/Documents/wager_ai/lol_data/data_extraction/2016_LoL_esports_match_data_from_OraclesElixir.csv\n",
      "Downloaded: /Users/micah.mathews/Documents/wager_ai/lol_data/data_extraction/2015_LoL_esports_match_data_from_OraclesElixir.csv\n",
      "Downloaded: /Users/micah.mathews/Documents/wager_ai/lol_data/data_extraction/2014_LoL_esports_match_data_from_OraclesElixir.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5w/5hzxm109285f2kz_4q6tm5yw0000gn/T/ipykernel_19220/2788787827.py:49: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined CSV file created: /Users/micah.mathews/Documents/wager_ai/lol_data/data_extraction/combined_csv_file.csv\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import os\n",
    "import pandas as pd\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "from googleapiclient.discovery import build\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "def download_csv_files_from_folder(folder_id):\n",
    "    # Set up Google Drive API credentials\n",
    "    credentials_file = '/Users/micah.mathews/Documents/machinelearning-392616-c2e002ef2244.json'\n",
    "    scopes = ['https://www.googleapis.com/auth/drive.readonly']\n",
    "    credentials = service_account.Credentials.from_service_account_file(credentials_file, scopes=scopes)\n",
    "    drive_service = build('drive', 'v3', credentials=credentials)\n",
    "\n",
    "    results = drive_service.files().list(q=f\"'{folder_id}' in parents and mimeType='text/csv'\",\n",
    "                                         fields='files(id, name)').execute()\n",
    "    csv_files = results.get('files', [])\n",
    "\n",
    "    download_directory = \"/Users/micah.mathews/Documents/wager_ai/lol_data/data_extraction\"\n",
    "\n",
    "    # Download the updated CSV files, overwriting existing files with the same names\n",
    "    for file in csv_files:\n",
    "        file_id = file['id']\n",
    "        file_name = file['name']\n",
    "        download_path = os.path.join(download_directory, file_name)\n",
    "\n",
    "        request = drive_service.files().get_media(fileId=file_id)\n",
    "        fh = io.FileIO(download_path, mode='wb')\n",
    "        downloader = MediaIoBaseDownload(fh, request)\n",
    "\n",
    "        done = False\n",
    "        while done is False:\n",
    "            status, done = downloader.next_chunk()\n",
    "\n",
    "        print(f\"Downloaded: {download_path}\")\n",
    "\n",
    "    combined_dfs = []\n",
    "    \n",
    "    # Create a combined DataFrame with selected columns\n",
    "    selected_columns = ['gameid', 'datacompleteness', 'url', 'league', 'year', 'split', 'playoffs', 'date',\n",
    "                        'game', 'patch', 'side', 'position', 'playername', 'teamname', 'result', 'champion']\n",
    "    \n",
    "    for file in csv_files:\n",
    "        file_name = file['name']\n",
    "        \n",
    "        # Check for files named from 2015 to 2023\n",
    "        if any(f\"{year}_LoL_esports_match_data_from_OraclesElixir\" in file_name for year in range(2015, 3000)):\n",
    "            file_path = os.path.join(download_directory, file_name)\n",
    "            df = pd.read_csv(file_path)\n",
    "            df = df[selected_columns]\n",
    "            combined_dfs.append(df)\n",
    "\n",
    "    combined_df = pd.concat(combined_dfs, ignore_index=True)\n",
    "\n",
    "    combined_csv_file = \"combined_csv_file.csv\"\n",
    "    combined_csv_path = os.path.join(download_directory, combined_csv_file)\n",
    "    \n",
    "    combined_df.to_csv(combined_csv_path, index=False)\n",
    "    print(f\"Combined CSV file created: {combined_csv_path}\")\n",
    "\n",
    "folder_id = '1gLSw0RLjBbtaNy0dgnGQDAZOHIgCe-HH'\n",
    "download_csv_files_from_folder(folder_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c55ad94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
